\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
% \PassOptionsToPackage{numbers, compress}{natbib}
% before loading nips_2017
%
% to avoid loading the natbib package, add option nonatbib:
% \usepackage[nonatbib]{nips_2017}

%\usepackage{nips_2017}

% to compile a camera-ready version, add the [final] option, e.g.:
 \usepackage[final]{nips_2017_abstract}

\usepackage[utf8]{inputenc} % allow utf-8 input
\usepackage[T1]{fontenc}    % use 8-bit T1 fonts
\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography

\title{Basketball Article Recommender\\
for Bleacher Report}

% The \author macro works with any number of authors. There are two
% commands used to separate the names and addresses of multiple
% authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to
% break the lines. Using \AND forces a line break at that point. So,
% if LaTeX puts 3 of 4 authors names on the first line, and the last
% on the second line, try using \AND instead of \And before the third
% author name.

\author{
  Stephen Albro\\
  Master of Business Analytics\\
  Massachusetts Institute of Technology\\
  Cambridge, MA 02139\\
  \texttt{salbro@mit.edu}\\
  %% examples of more authors
   \And
   Cyrille Combettes \\
   Master of Business Analytics\\
  Massachusetts Institute of Technology\\
  Cambridge, MA 02139\\
   \texttt{cyrille@mit.edu} \\
  %% \AND
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
  %% \And
  %% Coauthor \\
  %% Affiliation \\
  %% Address \\
  %% \texttt{email} \\
}

\begin{document}
% \nipsfinalcopy is no longer used

\maketitle

% \begin{abstract}
%   The abstract paragraph should be indented \nicefrac{1}{2}~inch
%   (3~picas) on both the left- and right-hand margins. Use 10~point
%   type, with a vertical spacing (leading) of 11~points.  The word
%   \textbf{Abstract} must be centered, bold, and in point size 12. Two
%   line spaces precede the abstract. The abstract must be limited to
%   one paragraph.
% \end{abstract}

\section{Motivation}

% This project aims at using machine learning to generate ESPN articles.
% The idea is to write a program to scrape a bunch of articles to form a training corpus,
% and then build machine learning algorithms to generate new articles.

As avid basketball fans, we have enjoyed reading a variety of NBA articles
during our busy year in the MBAn program
to keep up-to-date on the league. Bleacher Report, a primary digital destination
for sports article readers, contains well written articles, and we thought about returning the
favor.

In an age of cut-throat digital competition, it is vital for websites to retain visitors. The
hope for a Bleacher Report article reader is two-fold. First, that the visitor jumps from article to
article on the website, rather than returning to the search engine results page. Second, that the
visitor falls in love with the content and coverage of Bleacher Reportâ€™s articles, and develops a
loyalty to the website.

We feel that having a micro targeted article recommendation system would provide Bleacher 
Report with an analytics-based edge over its competitors. In this paper,
we develop a prototype for an article recommendation system using state of the art natural 
language processing techniques for both cleaning and analyzing Bleacher Report articles. Specifically,
we aim to cluster over 3000 Bleacher Report articles by testing three different approaches
for topic modeling: Word2Vec, Latent Dirichlet Allocation (LDA), 
and Non-negative Matrix Factorization (NMF).

\section{Data collection and preprocessing}

% We will query articles from the ESPN API, available at
% \url{http://www.espn.com/static/apis/devcenter/docs/headlines.html#what-it-returns}.
% There are parameters that we can use in the query to return news for a specific date,
% to disable specific information, to access to top stories as selected by ESPN editorial staff,
% to access to news for a particular sport,
% or to access to stories about a particular athlete, for example.

We queried Bleacher Report NBA
articles from last October 17, the start day of the 2017-2018 NBA season. Our entire query consisted of
joining words like \emph{basketball} and \emph{NBA} with all 30 teams and the top 25 active players:
we received 3,314 URLs in return.
We then wrote a script to request the webpage for each URL and scrape its content, picking the
paragraphs out of the HTML.

In the real world, data is never clean, and this is magnified in the case of textual data. There
were a number of preprocessing steps we had to do before our articles were ready for analysis. In
our cleaning efforts, we made decisions based on the purpose of our task: to cluster documents for
better recommendation power. In particular, a bag-of-words approach to cleaning was preferred 
over one that preserved punctuation and grammar.

\section{Key results}

The idea of our recommendation algorithm is to (1) generate topics from our corpus once for all
before (2)
recommending articles using a nearest-neighbor approach over the topic distributions of the reader's 
recent articles. We try both LDA and NMF, and it turns out LDA has the best results for our experiment.
Thus, we then explore the LDA-based recommmendation algorithm more in depth and display
insightful visualizations.

% \section{Impact}
% 
% The impact of this project is to evaluate if ESPN articles follow a recognizable pattern.
% It is widely known that an article on a basketball game, for example, is written during -- and even before! --
% the game, and we want to investigate to what extent the article is \emph{independant} of the specifics
% of the game: is the article a frame in which the reporter would just enter values for the score, the winning
% team, the losing team, and some lexical field words based on the reader's expected opinion? Or are the ESPN
% reporters true novelists? Answering this, we will assess if ESPN articles are a scam to put into the fake
% news category, or interesting and constructive information.

\end{document}
